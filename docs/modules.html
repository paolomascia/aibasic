<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Modules · AIbasic (v1.0)</title>
<link rel="stylesheet" href="style.css">
</head>
<body>
<header class="site-header">
  <div class="brandbar">
    <div class="inner">
      <a href="index.html" class="brand">
        <img src="logo_dark.png" alt="AIBASIC logo">
        <div class="titles">
          <div class="name">AIBASIC</div>
          <div class="tagline">Natural Language Programming</div>
        </div>
      </a>
    </div>
  </div>
  <div class="navbar">
    <div class="inner">
      <nav>
        <a href="manifesto.html">Manifesto</a>
        <a href="architecture.html">Architecture</a>
        <a href="language.html">Language</a>
        <a href="modules.html">Modules</a>
        <a href="control-flow.html">Control Flow</a>
        <a href="examples.html">Examples</a>
        <a href="changelog.html">Changelog</a>
      </nav>
    </div>
  </div>
</header>

<div class="container grid">
  <aside class="sidebar">
    <strong>Modules (24)</strong>
    <a href="#postgres">PostgreSQL</a>
    <a href="#mysql">MySQL</a>
    <a href="#mongodb">MongoDB</a>
    <a href="#cassandra">Cassandra</a>
    <a href="#clickhouse">ClickHouse</a>
    <a href="#neo4j">Neo4j</a>
    <a href="#timescaledb">TimescaleDB</a>
    <a href="#redis">Redis</a>
    <a href="#rabbitmq">RabbitMQ</a>
    <a href="#kafka">Kafka</a>
    <a href="#opensearch">OpenSearch</a>
    <a href="#elasticsearch">Elasticsearch</a>
    <a href="#email">Email</a>
    <a href="#s3">S3/MinIO</a>
    <a href="#aws">AWS</a>
    <a href="#ssh">SSH/SFTP</a>
    <a href="#vault">Vault</a>
    <a href="#compress">Compression</a>
    <a href="#api">REST API</a>
    <a href="#teams">Microsoft Teams</a>
    <a href="#slack">Slack</a>
    <a href="#terraform">Terraform</a>
    <a href="#docker">Docker</a>
    <a href="#kubernetes">Kubernetes</a>
  </aside>
  <main>
    <h1>Modules Reference</h1>
    <p class="muted">AIbasic includes 24 production-ready modules for databases, messaging, storage, networking, collaboration, analytics, cloud, IaC, containers, orchestration, and security.</p>

    <h2 id="postgres">1. PostgreSQL Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(postgres)</code></p>
      <p><strong>Purpose:</strong> Connect to PostgreSQL databases, execute queries, manage transactions</p>

      <h3>Configuration</h3>
      <pre><code>[postgres]
HOST = localhost
PORT = 5432
DATABASE = mydb
USERNAME = user
PASSWORD = pass</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (postgres) connect to database "mydb"
20 (postgres) execute query "SELECT * FROM users WHERE age > 18"
30 (postgres) insert record into users table with values
40 (postgres) update users set status = 'active' where id = 123
50 (postgres) begin transaction
60 (postgres) commit transaction
70 (postgres) rollback transaction
80 (postgres) close connection</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Connection pooling</li>
        <li>Parameterized queries (SQL injection protection)</li>
        <li>Transaction management</li>
        <li>Batch operations</li>
        <li>Result set to DataFrame conversion</li>
      </ul>
    </div>

    <h2 id="mysql">2. MySQL/MariaDB Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(mysql)</code></p>
      <p><strong>Purpose:</strong> MySQL and MariaDB database operations</p>

      <h3>Configuration</h3>
      <pre><code>[mysql]
HOST = localhost
PORT = 3306
DATABASE = mydb
USERNAME = user
PASSWORD = pass</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (mysql) connect to database "customers"
20 (mysql) query "SELECT name, email FROM users"
30 (mysql) insert into orders values (1, '2025-01-01', 100.50)
40 (mysql) update inventory set stock = stock - 1 where product_id = 5
50 (mysql) execute stored procedure "calculate_totals"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Compatible with MySQL and MariaDB</li>
        <li>Stored procedure support</li>
        <li>Prepared statements</li>
        <li>Connection pooling</li>
      </ul>
    </div>

    <h2 id="mongodb">3. MongoDB Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(mongodb)</code></p>
      <p><strong>Purpose:</strong> NoSQL document database operations</p>

      <h3>Configuration</h3>
      <pre><code>[mongodb]
CONNECTION_STRING = mongodb://localhost:27017
DATABASE = mydb
COLLECTION = products</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (mongodb) connect to collection "products"
20 (mongodb) find documents where price > 100
30 (mongodb) find one document with id "12345"
40 (mongodb) insert document with name "Product A" and price 99.99
50 (mongodb) update documents set category = "Electronics" where type = "gadget"
60 (mongodb) delete documents where expired is true
70 (mongodb) aggregate pipeline for sales analysis
80 (mongodb) create index on field "customer_id"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Find, insert, update, delete operations</li>
        <li>Aggregation pipelines</li>
        <li>Index management</li>
        <li>Bulk operations</li>
        <li>Document to DataFrame conversion</li>
      </ul>
    </div>

    <h2 id="cassandra">4. Cassandra Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(cassandra)</code></p>
      <p><strong>Purpose:</strong> Distributed NoSQL database for high-scale applications</p>

      <h3>Configuration</h3>
      <pre><code>[cassandra]
HOSTS = 127.0.0.1
PORT = 9042
KEYSPACE = analytics</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (cassandra) connect to keyspace "analytics"
20 (cassandra) execute query "SELECT * FROM events WHERE date > '2025-01-01'"
30 (cassandra) insert into events values (uuid, timestamp, data)
40 (cassandra) batch insert multiple records
50 (cassandra) use prepared statement for query</code></pre>

      <h3>Features</h3>
      <ul>
        <li>CQL query support</li>
        <li>Prepared statements</li>
        <li>Batch operations</li>
        <li>High-throughput writes</li>
      </ul>
    </div>

    <h2 id="clickhouse">5. ClickHouse Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(clickhouse)</code></p>
      <p><strong>Purpose:</strong> High-performance column-oriented analytics database for OLAP workloads</p>

      <h3>Configuration</h3>
      <pre><code>[clickhouse]
HOST = localhost
PORT = 8123
DATABASE = default
USERNAME = default
PASSWORD = your_password
COMPRESSION = lz4</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (clickhouse) query "SELECT * FROM events WHERE event_date = today()"
20 (clickhouse) batch insert into analytics from dataframe data
30 (clickhouse) create table events with MergeTree engine
40 (clickhouse) optimize table events final
50 (clickhouse) get stats for table events</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Extremely fast analytical queries (billions of rows)</li>
        <li>Column-oriented storage with excellent compression (10-20x)</li>
        <li>Batch inserts for high-performance data loading</li>
        <li>DataFrame integration (query to DataFrame, insert from DataFrame)</li>
        <li>Multiple table engines (MergeTree, SummingMergeTree, ReplacingMergeTree)</li>
        <li>Partitioning support (time-based and custom)</li>
        <li>Materialized views for pre-aggregated data</li>
        <li>LZ4/ZSTD compression for network efficiency</li>
        <li>Perfect for: Web analytics, log aggregation, time-series data, data warehousing</li>
      </ul>
    </div>

    <h2 id="neo4j">6. Neo4j Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(neo4j)</code></p>
      <p><strong>Purpose:</strong> Native graph database for highly connected data</p>

      <h3>Configuration</h3>
      <pre><code>[neo4j]
URI = bolt://localhost:7687
USERNAME = neo4j
PASSWORD = password
DATABASE = neo4j</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (neo4j) execute query "CREATE (p:Person {name: 'Alice', age: 30})"
20 (neo4j) create node with label "Person" and properties
30 (neo4j) create relationship from "Alice" to "Bob" type "KNOWS"
40 (neo4j) find path from "Alice" to "Charlie" max depth 3
50 (neo4j) execute query "MATCH (p:Person) WHERE p.age > 25 RETURN p"
60 (neo4j) query to dataframe "MATCH (p:Person)-[:WORKS_FOR]->(c:Company) RETURN p.name, c.name"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Cypher query language support</li>
        <li>Create, read, update, delete nodes and relationships</li>
        <li>Path finding and graph traversal</li>
        <li>Pattern matching (social networks, recommendations)</li>
        <li>Indexes and constraints (UNIQUE, EXISTS)</li>
        <li>DataFrame integration for analytics</li>
        <li>Batch operations for high-performance bulk imports</li>
        <li>Connection pooling</li>
        <li>Perfect for: Social networks, knowledge graphs, fraud detection, recommendation engines</li>
      </ul>
    </div>

    <h2 id="timescaledb">7. TimescaleDB Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(timescaledb)</code></p>
      <p><strong>Purpose:</strong> Time-series database (PostgreSQL extension) for IoT, monitoring, and analytics</p>

      <h3>Configuration</h3>
      <pre><code>[timescaledb]
HOST = localhost
PORT = 5432
DATABASE = tsdb
USERNAME = postgres
PASSWORD = password
POOL_SIZE = 5</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (timescaledb) create hypertable "sensor_data" with time column "time"
20 (timescaledb) insert sensor readings into hypertable
30 (timescaledb) time bucket query with 15-minute intervals
40 (timescaledb) create continuous aggregate for hourly summaries
50 (timescaledb) add compression policy compress after 7 days
60 (timescaledb) add retention policy keep for 30 days
70 (timescaledb) fill gaps in time-series data using LOCF
80 (timescaledb) get hypertable statistics</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Hypertables - Automatic time-based partitioning</li>
        <li>Continuous aggregates - Auto-updating materialized views</li>
        <li>Compression - 90%+ storage reduction</li>
        <li>Retention policies - Automatic data deletion</li>
        <li>Time-bucket queries - Efficient aggregations</li>
        <li>Gap filling - Fill missing data points</li>
        <li>Space partitioning - Multi-dimensional partitioning</li>
        <li>100% PostgreSQL compatible</li>
        <li>Perfect for: IoT data, monitoring, financial data, sensor data</li>
      </ul>
    </div>

    <h2 id="redis">8. Redis Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(redis)</code></p>
      <p><strong>Purpose:</strong> In-memory cache and data structure store</p>

      <h3>Configuration</h3>
      <pre><code>[redis]
HOST = localhost
PORT = 6379
DB = 0
PASSWORD = optional</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (redis) set key "user:1000" to value "John Doe"
20 (redis) get value from key "user:1000"
30 (redis) set key with expiration 3600 seconds
40 (redis) increment counter "visits"
50 (redis) decrement counter "stock"
60 (redis) push value to list "queue"
70 (redis) pop value from list "queue"
80 (redis) add member to set "tags"
90 (redis) check if member exists in set
100 (redis) delete key "old_data"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>String operations (get/set)</li>
        <li>Counter operations (incr/decr)</li>
        <li>List operations (push/pop)</li>
        <li>Set operations</li>
        <li>Hash operations</li>
        <li>TTL/expiration support</li>
        <li>Connection pooling</li>
      </ul>
    </div>

    <h2 id="rabbitmq">9. RabbitMQ Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(rabbitmq)</code></p>
      <p><strong>Purpose:</strong> Message queue for asynchronous processing</p>

      <h3>Configuration</h3>
      <pre><code>[rabbitmq]
HOST = localhost
PORT = 5672
USERNAME = guest
PASSWORD = guest
VIRTUAL_HOST = /</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (rabbitmq) publish message "Order #123" to queue "orders"
20 (rabbitmq) consume messages from queue "notifications"
30 (rabbitmq) declare exchange "events" type fanout
40 (rabbitmq) bind queue "alerts" to exchange "events"
50 (rabbitmq) acknowledge message
60 (rabbitmq) reject message and requeue</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Publish/consume messages</li>
        <li>Queue declaration and binding</li>
        <li>Exchange types (direct, fanout, topic)</li>
        <li>Message acknowledgment</li>
        <li>Durable queues</li>
      </ul>
    </div>

    <h2 id="kafka">10. Apache Kafka Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(kafka)</code></p>
      <p><strong>Purpose:</strong> Distributed streaming platform</p>

      <h3>Configuration</h3>
      <pre><code>[kafka]
BOOTSTRAP_SERVERS = localhost:9092
GROUP_ID = my-consumer-group</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (kafka) produce message to topic "user-events"
20 (kafka) consume messages from topic "logs"
30 (kafka) subscribe to topics "orders" and "payments"
40 (kafka) commit offset for consumer group
50 (kafka) seek to beginning of topic
60 (kafka) get topic metadata</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Producer API</li>
        <li>Consumer API with consumer groups</li>
        <li>Offset management</li>
        <li>Topic subscription</li>
        <li>Batch processing</li>
      </ul>
    </div>

    <h2 id="opensearch">11. OpenSearch Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(opensearch)</code></p>
      <p><strong>Purpose:</strong> Full-text search and analytics (OpenSearch/Elasticsearch compatible)</p>

      <h3>Configuration</h3>
      <pre><code>[opensearch]
HOSTS = https://localhost:9200
USERNAME = admin
PASSWORD = admin
VERIFY_CERTS = false</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (opensearch) index document in "products" index
20 (opensearch) search for "laptop" in all fields
30 (opensearch) search with filter where price < 1000
40 (opensearch) aggregate data by category
50 (opensearch) delete document by id
60 (opensearch) bulk index documents from dataframe
70 (opensearch) update document</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Full-text search</li>
        <li>Index management</li>
        <li>Aggregations</li>
        <li>Bulk operations</li>
        <li>Query DSL support</li>
      </ul>
    </div>

    <h2 id="elasticsearch">12. Elasticsearch Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(elasticsearch)</code></p>
      <p><strong>Purpose:</strong> Distributed search and analytics engine for full-text search and real-time data</p>

      <h3>Configuration</h3>
      <pre><code>[elasticsearch]
HOSTS = http://localhost:9200
USERNAME = elastic
PASSWORD = changeme
VERIFY_CERTS = false
TIMEOUT = 30</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (elasticsearch) create index "products" with mappings
20 (elasticsearch) index document in "products" index
30 (elasticsearch) search for "laptop" in all fields
40 (elasticsearch) search with query DSL {"match": {"description": "wireless"}}
50 (elasticsearch) range query where price between 50 and 100
60 (elasticsearch) bool query with must and filter conditions
70 (elasticsearch) aggregate by category with average price
80 (elasticsearch) bulk index documents from list
90 (elasticsearch) update document by id
100 (elasticsearch) delete documents matching query
110 (elasticsearch) search and return as dataframe</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Full-text search with fuzzy matching and wildcards</li>
        <li>Query DSL (match, term, range, bool, wildcard queries)</li>
        <li>Aggregations (terms, stats, histogram, date histogram)</li>
        <li>Index management (create, delete, mappings, aliases)</li>
        <li>Document CRUD operations</li>
        <li>Bulk operations for high-performance indexing</li>
        <li>Update/delete by query</li>
        <li>DataFrame integration for analytics</li>
        <li>Multi-field search and highlighting</li>
        <li>Cluster health monitoring and index statistics</li>
        <li>Perfect for: Application search, log analytics, e-commerce search, real-time analytics</li>
      </ul>
    </div>

    <h2 id="email">13. Email Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(email)</code></p>
      <p><strong>Purpose:</strong> Send emails with attachments</p>

      <h3>Configuration</h3>
      <pre><code>[email]
SMTP_HOST = smtp.gmail.com
SMTP_PORT = 587
USERNAME = your-email@gmail.com
PASSWORD = your-app-password
FROM_EMAIL = your-email@gmail.com
USE_TLS = true</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (email) send email to "user@example.com"
20 (email) set subject to "Daily Report"
30 (email) set body to "Please find the attached report"
40 (email) attach file "report.pdf"
50 (email) send HTML email with template
60 (email) send to multiple recipients
70 (email) add CC and BCC recipients</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Plain text and HTML emails</li>
        <li>File attachments</li>
        <li>Multiple recipients (To, CC, BCC)</li>
        <li>TLS/SSL support</li>
        <li>Template support</li>
      </ul>
    </div>

    <h2 id="s3">14. S3/MinIO Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(s3)</code></p>
      <p><strong>Purpose:</strong> Object storage (AWS S3, MinIO, DigitalOcean Spaces, Wasabi)</p>

      <h3>Configuration</h3>
      <pre><code>[s3]
AWS_ACCESS_KEY_ID = your-access-key
AWS_SECRET_ACCESS_KEY = your-secret-key
BUCKET_NAME = my-bucket
REGION = us-east-1
# For MinIO:
# ENDPOINT_URL = http://localhost:9000</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (s3) upload file "data.csv" to bucket "my-bucket"
20 (s3) upload to path "reports/2025/data.csv"
30 (s3) download object "report.pdf" from bucket
40 (s3) list objects in bucket with prefix "2025/"
50 (s3) delete object "old_file.csv"
60 (s3) generate presigned URL for object valid for 3600 seconds
70 (s3) check if object exists
80 (s3) get object metadata</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Upload/download files</li>
        <li>Multipart uploads for large files</li>
        <li>Presigned URLs for temporary access</li>
        <li>List/delete operations</li>
        <li>Server-side encryption</li>
        <li>Compatible with S3, MinIO, Spaces, Wasabi</li>
      </ul>
    </div>

    <h2 id="aws">15. AWS Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(aws)</code></p>
      <p><strong>Purpose:</strong> Comprehensive Amazon Web Services integration (S3, DynamoDB, SQS, SNS, Lambda, Secrets Manager, CloudWatch)</p>

      <h3>Configuration</h3>
      <pre><code>[aws]
AWS_ACCESS_KEY_ID = your-access-key
AWS_SECRET_ACCESS_KEY = your-secret-key
AWS_REGION = us-east-1
DEFAULT_S3_BUCKET = my-bucket
DEFAULT_DYNAMODB_TABLE = my-table</code></pre>

      <h3>Common Operations</h3>
      <pre><code># S3 Operations
10 (aws) upload file "data.csv" to S3 bucket "my-bucket"
20 (aws) download from S3 bucket "my-bucket" key "data.csv"
30 (aws) list S3 objects in bucket "my-bucket"

# DynamoDB Operations
40 (aws) put item into DynamoDB table "users" with data
50 (aws) get item from DynamoDB table "users" with key
60 (aws) query DynamoDB table "users" where user_id equals "123"

# SQS Operations
70 (aws) send message to SQS queue "orders-queue"
80 (aws) receive messages from SQS queue "orders-queue"

# SNS Operations
90 (aws) publish to SNS topic with message "Alert"

# Lambda Operations
100 (aws) invoke Lambda function "my-function" with payload

# Secrets Manager
110 (aws) get secret from Secrets Manager "db-credentials"

# CloudWatch
120 (aws) put CloudWatch metric "OrderCount" value 150</code></pre>

      <h3>Features</h3>
      <ul>
        <li>S3 - Object storage (upload, download, list, presigned URLs)</li>
        <li>DynamoDB - NoSQL database (put, get, query, scan, delete)</li>
        <li>SQS - Message queuing (send, receive, delete messages)</li>
        <li>SNS - Pub/sub notifications (publish to topics)</li>
        <li>Lambda - Invoke serverless functions (sync/async)</li>
        <li>Secrets Manager - Secure credential storage</li>
        <li>CloudWatch - Custom metrics and monitoring</li>
        <li>LocalStack support for local development</li>
        <li>Automatic credential management (IAM, env, config)</li>
        <li>Connection pooling and retry logic</li>
        <li>Perfect for: Cloud-native apps, serverless, data pipelines, microservices</li>
      </ul>
    </div>

    <h2 id="ssh">16. SSH/SFTP Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(ssh)</code></p>
      <p><strong>Purpose:</strong> Remote server access and file transfer</p>

      <h3>Configuration</h3>
      <pre><code>[ssh]
HOST = server.example.com
PORT = 22
USERNAME = admin
PASSWORD = password
# OR use key-based auth:
# KEY_FILE = ~/.ssh/id_rsa</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (ssh) connect to server "192.168.1.100"
20 (ssh) execute command "uptime"
30 (ssh) execute command "df -h"
40 (ssh) transfer file "local.txt" to "/remote/path/file.txt"
50 (ssh) download file from "/var/log/app.log" to "local.log"
60 (ssh) execute multiple commands
70 (ssh) create SSH tunnel
80 (ssh) disconnect</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Command execution</li>
        <li>SFTP file transfer (upload/download)</li>
        <li>Password and key-based authentication</li>
        <li>SSH tunneling/port forwarding</li>
        <li>Sudo command support</li>
      </ul>
    </div>

    <h2 id="vault">17. HashiCorp Vault Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(vault)</code></p>
      <p><strong>Purpose:</strong> Secure secrets management</p>

      <h3>Configuration</h3>
      <pre><code>[vault]
VAULT_ADDR = http://localhost:8200
VAULT_TOKEN = your-vault-token
# OR use AppRole:
# ROLE_ID = your-role-id
# SECRET_ID = your-secret-id</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (vault) read secret from path "secret/database/prod"
20 (vault) get field "username" from secret
30 (vault) get field "password" from secret
40 (vault) write secret to path "secret/api-keys"
50 (vault) write with data {"key": "value", "token": "abc123"}
60 (vault) delete secret at path "secret/old-credentials"
70 (vault) list secrets at path "secret/"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Read/write/delete secrets</li>
        <li>Token and AppRole authentication</li>
        <li>KV v1 and v2 support</li>
        <li>Dynamic secrets support</li>
        <li>Secret versioning</li>
      </ul>
    </div>

    <h2 id="compress">18. Compression Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(compress)</code></p>
      <p><strong>Purpose:</strong> File compression and extraction</p>

      <h3>Configuration</h3>
      <p>No configuration required</p>

      <h3>Common Operations</h3>
      <pre><code>10 (compress) compress file "data.txt" to "data.zip"
20 (compress) compress folder "reports" to "reports.tar.gz"
30 (compress) extract archive "data.zip" to "output/"
40 (compress) create password-protected zip with password "secret"
50 (compress) list contents of archive "backup.tar.gz"
60 (compress) add file to existing archive</code></pre>

      <h3>Features</h3>
      <ul>
        <li>ZIP, TAR, TAR.GZ, TAR.BZ2 formats</li>
        <li>Compress files and folders</li>
        <li>Extract archives</li>
        <li>Password-protected archives</li>
        <li>List archive contents</li>
      </ul>
    </div>

    <h2 id="api">19. REST API Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(api)</code></p>
      <p><strong>Purpose:</strong> HTTP client for REST API calls</p>

      <h3>Configuration</h3>
      <pre><code>[restapi]
BASE_URL = https://api.example.com
AUTH_METHOD = bearer
BEARER_TOKEN = your-token
# OR use other auth methods:
# AUTH_METHOD = basic
# USERNAME = user
# PASSWORD = pass</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (api) GET request to "https://api.example.com/users"
20 (api) POST data to "/users" with JSON payload
30 (api) PUT request to "/users/123" with update data
40 (api) DELETE request to "/users/123"
50 (api) set bearer token for authentication
60 (api) set custom headers "X-API-Key: abc123"
70 (api) upload file to "/upload" endpoint
80 (api) download file from "/files/report.pdf"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>GET, POST, PUT, DELETE, PATCH methods</li>
        <li>Multiple authentication: Bearer, Basic, API Key, OAuth2</li>
        <li>Custom headers</li>
        <li>JSON/form data payloads</li>
        <li>File uploads/downloads</li>
        <li>Retry logic with exponential backoff</li>
        <li>Session management</li>
      </ul>
    </div>

    <h2 id="teams">20. Microsoft Teams Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(teams)</code></p>
      <p><strong>Purpose:</strong> Send messages, alerts, and adaptive cards to Microsoft Teams channels</p>

      <h3>Configuration</h3>
      <pre><code>[teams]
# Option 1: Webhook (simple)
WEBHOOK_URL = https://your-org.webhook.office.com/webhookb2/...

# Option 2: App-based (advanced)
TENANT_ID = xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
CLIENT_ID = xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
CLIENT_SECRET = your-client-secret
TEAM_ID = xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
CHANNEL_ID = 19:xxx@thread.tacv2</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (teams) send message to channel
20 (teams) set title to "Pipeline Complete"
30 (teams) set text to "ETL job finished successfully"
40 (teams) set color to "107C10"

50 (teams) send alert with message "High CPU usage"
60 (teams) set severity to "warning"
70 (teams) set title to "System Alert"

80 (teams) send status message
90 (teams) set title to "Database Backup"
100 (teams) add field "Size" with value "150 GB"
110 (teams) add field "Duration" with value "45 minutes"

120 (teams) send adaptive card with title "Sales Report"
130 (teams) add fact "Revenue" with value "$1.2M"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Simple text messages with color coding</li>
        <li>Alert messages (info, warning, error, success)</li>
        <li>Status messages with multiple fields</li>
        <li>Adaptive Cards with facts and sections</li>
        <li>Webhook and Microsoft Graph API support</li>
        <li>Automatic retries with exponential backoff</li>
        <li>Threaded notifications</li>
      </ul>
    </div>

    <h2 id="slack">21. Slack Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(slack)</code></p>
      <p><strong>Purpose:</strong> Send messages, alerts, blocks, and files to Slack channels</p>

      <h3>Configuration</h3>
      <pre><code>[slack]
# Option 1: Webhook (simple)
WEBHOOK_URL = https://hooks.slack.com/services/T00000000/B00000000/XXX

# Option 2: Bot Token (advanced)
BOT_TOKEN = xoxb-your-bot-token-here
DEFAULT_CHANNEL = #general</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (slack) send message to channel "#general"
20 (slack) set text to "Hello from AIbasic!"
30 (slack) set username to "Deploy Bot"
40 (slack) set icon emoji to ":rocket:"

50 (slack) send alert with message "High CPU usage detected"
60 (slack) set severity to "warning"
70 (slack) set title to "System Alert"

80 (slack) send status message
90 (slack) set title to "Database Backup"
100 (slack) add field "Database" with value "production_db"
110 (slack) add field "Size" with value "150 GB"

120 (slack) create block message
130 (slack) add header block with text "Pipeline Report"
140 (slack) add divider block
150 (slack) add section block with text "*Status:* Success"
160 (slack) send blocks to channel "#pipelines"

170 (slack) upload file "report.csv"
180 (slack) set title to "Daily Report"
190 (slack) set initial comment to "Today's data"</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Simple messages with custom icons and usernames</li>
        <li>Alert messages with color coding (info, warning, error, success)</li>
        <li>Status messages with fields</li>
        <li>Rich messages with attachments</li>
        <li>Block Kit messages (headers, sections, dividers, fields)</li>
        <li>File uploads to channels</li>
        <li>Message updates and deletion</li>
        <li>Emoji reactions</li>
        <li>Threaded messages</li>
        <li>Webhook and bot token support</li>
        <li>Automatic retries with exponential backoff</li>
      </ul>
    </div>

    <h2 id="terraform">22. Terraform Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(terraform)</code></p>
      <p><strong>Purpose:</strong> Manage infrastructure as code (IaC) using HashiCorp Terraform</p>

      <h3>Configuration</h3>
      <pre><code>[terraform]
WORKING_DIR = ./terraform
AUTO_APPROVE = false
PARALLELISM = 10
DEFAULT_WORKSPACE = default
BACKEND_TYPE = s3
BACKEND_CONFIG = {"bucket": "my-tf-state", "key": "terraform.tfstate", "region": "us-east-1"}</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (terraform) initialize terraform in directory "./terraform"
20 (terraform) validate terraform configuration
30 (terraform) format terraform configuration files
40 (terraform) create terraform plan and save to "plan.out"
50 (terraform) apply terraform configuration with auto approve

60 (terraform) get all terraform outputs
70 (terraform) get terraform output "instance_ip"

80 (terraform) list all terraform workspaces
90 (terraform) create new terraform workspace "staging"
100 (terraform) select terraform workspace "staging"

110 (terraform) list all resources in terraform state
120 (terraform) show terraform state for resource "aws_instance.web"
130 (terraform) refresh terraform state

140 (terraform) import terraform resource at "aws_instance.existing" with id "i-1234567890"

150 (terraform) destroy terraform with auto approve</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Full Terraform CLI wrapper</li>
        <li>Multi-cloud support (AWS, Azure, GCP, 1000+ providers)</li>
        <li>Workspace management for environment isolation</li>
        <li>State management operations</li>
        <li>Backend configuration (S3, Azure, GCS, local)</li>
        <li>Variable management</li>
        <li>Plan, apply, destroy operations</li>
        <li>Import existing resources</li>
        <li>Validation and formatting</li>
        <li>Output value retrieval</li>
      </ul>
    </div>

    <h2 id="docker">23. Docker Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(docker)</code></p>
      <p><strong>Purpose:</strong> Manage Docker containers, images, volumes, and networks</p>

      <h3>Configuration</h3>
      <pre><code>[docker]
DOCKER_HOST = unix:///var/run/docker.sock
TLS_VERIFY = false
TIMEOUT = 60
DEFAULT_REGISTRY = docker.io
REGISTRY_USERNAME = your_username
REGISTRY_PASSWORD = your_password</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (docker) run container from image "nginx:latest" named "web-server" in detached mode
20 (docker) list all running containers
30 (docker) stop container "web-server"
40 (docker) remove container "web-server"

50 (docker) pull image "alpine" with tag "latest"
60 (docker) list all images
70 (docker) remove image "alpine:latest"

80 (docker) create volume "data-volume"
90 (docker) list all volumes
100 (docker) remove volume "data-volume"

110 (docker) create network "app-network" with driver "bridge"
120 (docker) list all networks
130 (docker) remove network "app-network"

140 (docker) get logs from container "web-server" tail 50 lines
150 (docker) exec command "whoami" in container "web-server"
160 (docker) get stats from container "web-server"

170 (docker) get system info
180 (docker) prune all system resources</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Container lifecycle management (run, start, stop, restart, remove)</li>
        <li>Image management (pull, build, push, tag, remove)</li>
        <li>Volume operations for persistent storage</li>
        <li>Network management for multi-container communication</li>
        <li>Container execution (exec commands)</li>
        <li>Logs and stats monitoring</li>
        <li>Health checks and pause/unpause</li>
        <li>Resource limits and restart policies</li>
        <li>Docker Hub search and registry operations</li>
        <li>System-wide cleanup and pruning</li>
      </ul>
    </div>

    <h2 id="kubernetes">24. Kubernetes Module</h2>
    <div class="panel">
      <p><strong>Task Type:</strong> <code>(kubernetes)</code></p>
      <p><strong>Purpose:</strong> Manage Kubernetes cluster resources (pods, deployments, services, etc.)</p>

      <h3>Configuration</h3>
      <pre><code>[kubernetes]
KUBECONFIG_PATH = ~/.kube/config
CONTEXT = default
NAMESPACE = default
API_SERVER = https://kubernetes.default.svc
TOKEN = <service-account-token>
VERIFY_SSL = true</code></pre>

      <h3>Common Operations</h3>
      <pre><code>10 (kubernetes) create pod named "app-pod" from image "nginx:latest"
20 (kubernetes) list all pods in namespace "default"
30 (kubernetes) delete pod "app-pod"

40 (kubernetes) create deployment named "web-app" from image "nginx:latest"
50 (kubernetes) with 3 replicas
60 (kubernetes) scale deployment "web-app" to 5 replicas
70 (kubernetes) rollout restart deployment "web-app"
80 (kubernetes) delete deployment "web-app"

90 (kubernetes) create service named "web-service" on port 80 target port 80
100 (kubernetes) with type "LoadBalancer"
110 (kubernetes) list all services
120 (kubernetes) delete service "web-service"

130 (kubernetes) create configmap named "app-config" with data config_data
140 (kubernetes) create secret named "app-secrets" with data secret_data

150 (kubernetes) create namespace "production"
160 (kubernetes) list all namespaces
170 (kubernetes) delete namespace "production"

180 (kubernetes) get logs from pod "app-pod" tail 100 lines
190 (kubernetes) exec command list "whoami" in pod "app-pod"
200 (kubernetes) get cluster info</code></pre>

      <h3>Features</h3>
      <ul>
        <li>Pod lifecycle management (create, list, delete, logs, exec)</li>
        <li>Deployment management (create, scale, rollout, delete)</li>
        <li>Service management (ClusterIP, NodePort, LoadBalancer)</li>
        <li>ConfigMap and Secret management</li>
        <li>Namespace isolation and multi-tenancy</li>
        <li>Resource monitoring and events</li>
        <li>Cluster information and node management</li>
        <li>Label-based resource selection</li>
        <li>Support for kubeconfig and in-cluster auth</li>
        <li>Multi-context cluster management</li>
      </ul>
    </div>

    <div class="panel">
      <h3>Module Usage Tips</h3>
      <ul>
        <li>Configure modules in <code>aibasic.conf</code> before use</li>
        <li>Use task type hints: <code>(postgres)</code>, <code>(mongodb)</code>, <code>(s3)</code>, <code>(terraform)</code>, <code>(docker)</code>, <code>(kubernetes)</code></li>
        <li>Combine modules for powerful workflows (e.g., Postgres → DataFrame → S3)</li>
        <li>Use error handling (<code>ON ERROR GOTO</code>) with I/O operations</li>
        <li>Close connections explicitly or rely on automatic cleanup</li>
      </ul>
    </div>
  </main>
</div>

<div class="container" style="border-top:1px solid var(--border);margin-top:2rem;padding-top:1rem;color:var(--muted)">
  © 2025 AIbasic v1.0 — Complete documentation with 24 integrated modules
</div>
<script src="script.js"></script>
</body></html>
